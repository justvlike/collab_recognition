Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ°: ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ÑĞ²ĞµÑ€Ñ‚Ğ¾Ñ‡Ğ½ÑƒÑ ĞĞ¡ Ğ´Ğ»Ñ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼ÑƒĞ·Ñ‹ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¿Ğ¾ Ğ°ÑƒĞ´Ğ¸Ğ¾Ğ´Ğ¾Ñ€Ğ¾Ğ¶ĞºĞµ, Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½ÑƒÑ‚ÑŒ Ğ¿Ñ€Ğ¸ĞµĞ¼Ğ»ĞµĞ¼Ğ¾Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸.\ Ğ”Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾:\
1. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ² Ğ¿Ñ€Ğ¸Ğ³Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ĞĞ¡ Ğ²Ğ¸Ğ´\
2. ĞĞ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑĞµÑ‚ÑŒ, Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½ÑƒĞ² Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ (Ğ²Ğ¾Ğ·Ñ€Ğ°ÑÑ‚Ğ°ÑÑ‰Ğ°Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ)

Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ´ Ğ¸ README: https://github.com/justvlike/collab_recognition

ĞŸÑ€Ğ¸Ğ²ÑĞ·ĞºĞ° Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğ³Ğ¾ IRMAS c GDrive\
IRMAS Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ Ğ´Ğ»Ñ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾ ÑÑÑ‹Ğ»ĞºĞµ https://zenodo.org/records/1290750#.WzCwSRyxXMU \
Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ IRMAS-TrainingData.zip


```python
from google.colab import drive

# ĞŸÑ€Ğ¸Ğ²ÑĞ·ĞºĞ° Google Drive
drive.mount('/content/drive')

```

    Mounted at /content/drive
    

ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ°, Ğ¿Ğ¾Ğ´Ñ‚ÑĞ½ÑƒÑ‚Ñ‹ Ğ»Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ñ‹. Ğ•ÑĞ»Ğ¸ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ - Ğ² ÑĞ¾ÑÑ‚Ğ°Ğ²Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ğ² IRMAS-TrainingData.zip


```python
import os

# Ğ’Ñ‹Ğ²Ğ¾Ğ´ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Google Drive
os.listdir('/content/drive/My Drive/University/Maga')

```




    ['ADDITIONS 1st SEMESTER.gdoc',
     'MASTERS 1st SEMESTER.gdoc',
     'IRMAS-TrainingData.zip']



Ğ Ğ°Ğ·Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°Ñ†Ğ¸Ñ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°, Ğ¿Ğ¾Ğ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² ÑĞ¾Ğ¾ÑÑ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ


```python
import zipfile

zip_file_path = '/content/drive/My Drive/University/Maga/IRMAS-TrainingData.zip'
extract_folder = '/content/irmas_dataset'

# Ğ Ğ°Ğ·Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

# Ğ’Ñ‹Ğ²Ğ¾Ğ´ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
os.listdir(extract_folder)

```




    ['IRMAS-TrainingData']



ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ Python


```python
!pip show tensorflow

```

    Name: tensorflow
    Version: 2.17.1
    Summary: TensorFlow is an open source machine learning framework for everyone.
    Home-page: https://www.tensorflow.org/
    Author: Google Inc.
    Author-email: packages@tensorflow.org
    License: Apache 2.0
    Location: /usr/local/lib/python3.10/dist-packages
    Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt
    Required-by: dopamine_rl, tf_keras
    


```python
!pip install librosa matplotlib tensorflow numpy

```

    Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)
    Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.0)
    Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)
    Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)
    Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)
    Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)
    Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)
    Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)
    Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)
    Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)
    Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.13.0)
    Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)
    Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)
    Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)
    Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)
    Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)
    Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)
    Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)
    Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)
    Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.8)
    Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)
    Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.1.0)
    Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.1)
    Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)
    Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)
    Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)
    Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.12.23)
    Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)
    Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)
    Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)
    Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)
    Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)
    Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)
    Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)
    Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)
    Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)
    Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)
    Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)
    Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)
    Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.69.0)
    Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)
    Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)
    Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)
    Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)
    Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)
    Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)
    Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)
    Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)
    Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)
    Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)
    Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)
    Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)
    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)
    Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)
    Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)
    Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)
    Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)
    Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)
    Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)
    Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)
    Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)
    Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)
    Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)
    

Ğ£Ğ±ĞµĞ´Ğ¸Ñ‚ÑŒÑÑ, Ñ‡Ñ‚Ğ¾ Ğ²ÑĞµ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ½Ğ¾ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¸ Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ Ğ¿Ğ°Ğ¿Ğ¾Ğº ÑĞ¾Ğ±Ğ»ÑĞ´ĞµĞ½Ğ° - Ğ²Ğ°Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¸ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ wav Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ² ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ Ğ¿Ğ¾Ğ·Ğ¶Ğµ


```python
import os

# Ğ£ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ½ĞµĞ¿Ğ¾ÑÑ€ĞµĞ´ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ Ğ²Ğ½ÑƒÑ‚Ñ€ÑŒ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ°
dataset_path = '/content/irmas_dataset/'
training_path = os.path.join(dataset_path, 'IRMAS-TrainingData')

# Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ¿Ğ¾Ğ´ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ¸
os.listdir(training_path)

```




    ['cel',
     'pia',
     'voi',
     'flu',
     'cla',
     'org',
     'tru',
     'gel',
     'gac',
     'sax',
     'vio',
     'README.txt']



Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ² ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ


```python
import librosa
import numpy as np

def load_audio_and_convert_to_spectrogram(audio_file, n_mels=128):
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ‡ĞµÑ€ĞµĞ· librosa
    y, sr = librosa.load(audio_file, sr=None)  # Load with original sampling rate
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Mel-spectrogram
    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)
    # ĞŸĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ² log scale Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
    log_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)
    return log_spectrogram

```

ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ - Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ² ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ


```python
import glob

def prepare_training_data(training_path, n_mels=128):
    X = []  # Features (spectrograms)
    y = []  # Labels (instrument classes)

    # ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ¼ Ğ² ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğ¸ Ñ Ğ¿Ğ°Ğ¿ĞºĞ°Ğ¼Ğ¸ Ğ² Ğ°Ñ€Ñ…Ğ¸Ğ²Ğµ
    instrument_map = {
        'cel': 0, 'cla': 1, 'flu': 2, 'gac': 3, 'gel': 4,
        'org': 5, 'pia': 6, 'sax': 7, 'tru': 8, 'vio': 9, 'voi': 10
    }

    # ĞŸÑ€Ğ¾Ñ…Ğ¾Ğ´ Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ Ğ¿Ğ¾Ğ´ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ°Ğ¼ Ğ¸ Ğ½ĞµĞ¿Ğ¾ÑÑ€ĞµĞ´ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
    for instrument, label in instrument_map.items():
        folder_path = os.path.join(training_path, instrument)
        for audio_file in glob.glob(os.path.join(folder_path, '*.wav')):
            spectrogram = load_audio_and_convert_to_spectrogram(audio_file, n_mels=n_mels)
            X.append(spectrogram)
            y.append(label)

    return np.array(X), np.array(y)

# ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ²Ñ‹Ğ·Ğ¾Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
X, y = prepare_training_data(training_path)
print(f"Data prepared: {X.shape}, Labels: {y.shape}")
```

    Data prepared: (6705, 128, 259), Labels: (6705,)
    

ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼, Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ² Ğ´Ğ»Ñ ĞĞ¡


```python
from sklearn.model_selection import train_test_split

# ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼ Ğº Ğ¾Ğ±Ğ»Ğ°Ñ‚ÑÑ‚ÑĞ¼ [0, 1]
X = X / np.max(X)

# Ğ Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (80% Ğ½Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ, 20% Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºÑƒ)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€ Ğ´Ğ»Ñ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞµĞ³Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ²ĞµÑ€Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ ĞĞ¡
X_train = X_train[..., np.newaxis]
X_val = X_val[..., np.newaxis]

print(f"Training data: {X_train.shape}, Validation data: {X_val.shape}")

```

    Training data: (5364, 128, 259, 1), Validation data: (1341, 128, 259, 1)
    

ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ Ğ¸ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° ĞĞ¡ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…


```python
import tensorflow as tf
from tensorflow.keras import layers, models

# ĞœĞ¾Ğ´ĞµĞ»ÑŒ ÑĞ²ĞµÑ€Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ ĞĞ¡
def build_model(input_shape, num_classes):
    model = models.Sequential([
        # ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ ÑĞ²ĞµÑ€Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ±Ğ»Ğ¾Ğº
        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.3),

        # Ğ’Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ ÑĞ²ĞµÑ€Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ±Ğ»Ğ¾Ğº
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.3),

        # Ğ¢Ñ€ĞµÑ‚Ğ¸Ğ¹ ÑĞ²ĞµÑ€Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ±Ğ»Ğ¾Ğº
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.3),

        # Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ¸
        layers.GlobalAveragePooling2D(),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

```


```python
from tensorflow.keras.utils import to_categorical

# ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ y_train Ğ¸ y_val Ğ² Ğ±Ğ¾Ğ»ĞµĞµ ÑƒĞ´Ğ¾Ğ±Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚.
y_train = to_categorical(y_train, num_classes=len(set(y)))
y_val = to_categorical(y_val, num_classes=len(set(y)))

```


```python
# Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
input_shape = X_train.shape[1:]  # Ğ Ğ°Ğ·Ğ¼ĞµÑ€ ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼
num_classes = len(set(y))  # ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ‚Ğ¸Ğ¿Ğ¾Ğ² ĞºĞ»Ğ°ÑÑĞ¾Ğ²
model = build_model(input_shape, num_classes)
model.summary()

# ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=10,  # Ğ‘Ğ¾Ğ»ÑŒÑˆĞµ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ¾Ğ² - ÑĞ¸Ğ»ÑŒĞ½ĞµĞµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ
    batch_size=32
)

```


<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential_1"</span>
</pre>




<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ<span style="font-weight: bold"> Layer (type)                         </span>â”ƒ<span style="font-weight: bold"> Output Shape                </span>â”ƒ<span style="font-weight: bold">         Param # </span>â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ conv2d_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)                    â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>, <span style="color: #00af00; text-decoration-color: #00af00">259</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)        â”‚             <span style="color: #00af00; text-decoration-color: #00af00">320</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_3                â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>, <span style="color: #00af00; text-decoration-color: #00af00">259</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)        â”‚             <span style="color: #00af00; text-decoration-color: #00af00">128</span> â”‚
â”‚ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)                 â”‚                             â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)       â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>, <span style="color: #00af00; text-decoration-color: #00af00">129</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)         â”‚               <span style="color: #00af00; text-decoration-color: #00af00">0</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)                  â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>, <span style="color: #00af00; text-decoration-color: #00af00">129</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)         â”‚               <span style="color: #00af00; text-decoration-color: #00af00">0</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)                    â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>, <span style="color: #00af00; text-decoration-color: #00af00">129</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)         â”‚          <span style="color: #00af00; text-decoration-color: #00af00">18,496</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_4                â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>, <span style="color: #00af00; text-decoration-color: #00af00">129</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)         â”‚             <span style="color: #00af00; text-decoration-color: #00af00">256</span> â”‚
â”‚ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)                 â”‚                             â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)       â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)          â”‚               <span style="color: #00af00; text-decoration-color: #00af00">0</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_5 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)                  â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)          â”‚               <span style="color: #00af00; text-decoration-color: #00af00">0</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)                    â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)         â”‚          <span style="color: #00af00; text-decoration-color: #00af00">73,856</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_5                â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)         â”‚             <span style="color: #00af00; text-decoration-color: #00af00">512</span> â”‚
â”‚ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)                 â”‚                             â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_5 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)       â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">16</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)         â”‚               <span style="color: #00af00; text-decoration-color: #00af00">0</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_6 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)                  â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">16</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)         â”‚               <span style="color: #00af00; text-decoration-color: #00af00">0</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooling2d_1           â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)                 â”‚               <span style="color: #00af00; text-decoration-color: #00af00">0</span> â”‚
â”‚ (<span style="color: #0087ff; text-decoration-color: #0087ff">GlobalAveragePooling2D</span>)             â”‚                             â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_2 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                      â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)                 â”‚          <span style="color: #00af00; text-decoration-color: #00af00">33,024</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_7 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)                  â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)                 â”‚               <span style="color: #00af00; text-decoration-color: #00af00">0</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                      â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">11</span>)                  â”‚           <span style="color: #00af00; text-decoration-color: #00af00">2,827</span> â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</pre>




<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">129,419</span> (505.54 KB)
</pre>




<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">128,971</span> (503.79 KB)
</pre>




<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">448</span> (1.75 KB)
</pre>



    Epoch 1/10
    [1m168/168[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m754s[0m 4s/step - accuracy: 0.2066 - loss: 2.2685 - val_accuracy: 0.1193 - val_loss: 2.9341
    Epoch 2/10
    [1m168/168[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m755s[0m 4s/step - accuracy: 0.2839 - loss: 2.0398 - val_accuracy: 0.1506 - val_loss: 3.7466
    Epoch 3/10
    [1m168/168[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m776s[0m 4s/step - accuracy: 0.3483 - loss: 1.8786 - val_accuracy: 0.1849 - val_loss: 2.5960
    Epoch 4/10
    [1m168/168[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m736s[0m 4s/step - accuracy: 0.4191 - loss: 1.6926 - val_accuracy: 0.1842 - val_loss: 2.5380
    Epoch 5/10
    [1m168/168[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m748s[0m 4s/step - accuracy: 0.4927 - loss: 1.5033 - val_accuracy: 0.3177 - val_loss: 2.0202
    Epoch 6/10
    [1m168/168[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m746s[0m 4s/step - accuracy: 0.5239 - loss: 1.3812 - val_accuracy: 0.3363 - val_loss: 2.1130
    Epoch 7/10
    [1m168/168[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m725s[0m 4s/step - accuracy: 0.5541 - loss: 1.3026 - val_accuracy: 0.2483 - val_loss: 3.1002
    Epoch 8/10
    [1m168/168[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m746s[0m 4s/step - accuracy: 0.5759 - loss: 1.2399 - val_accuracy: 0.3125 - val_loss: 2.8201
    Epoch 9/10
    [1m168/168[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m741s[0m 4s/step - accuracy: 0.5953 - loss: 1.1768 - val_accuracy: 0.3512 - val_loss: 2.2399
    Epoch 10/10
    [1m168/168[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m722s[0m 4s/step - accuracy: 0.6235 - loss: 1.1288 - val_accuracy: 0.6145 - val_loss: 1.1670
    

ĞŸĞ¾ÑÑ‚Ñ€Ğ¾Ğ¸Ğ¼ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸


```python
import matplotlib.pyplot as plt

# Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.show()

# Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()

```


    
![png](recog_doc_files/recog_doc_24_0.png)
    



    
![png](recog_doc_files/recog_doc_24_1.png)
    


ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ ĞµĞµ Ğ¾Ğ±Ñ€Ğ°Ğ·


```python
# Ğ¢Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ
val_loss, val_accuracy = model.evaluate(X_val, y_val)
print(f"Validation Accuracy: {val_accuracy * 100:.2f}%")

# Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
model.save('/content/instrument_classifier_model.h5')
```

    [1m42/42[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m36s[0m 861ms/step - accuracy: 0.6296 - loss: 1.1444
    

    WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
    

    Validation Accuracy: 61.45%
    

Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğµ


```python
import matplotlib.pyplot as plt
import librosa.display

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸
def load_audio_and_convert_to_spectrogram_debug(audio_file, n_mels=128):
    import librosa
    import numpy as np

    try:
        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾
        y, sr = librosa.load(audio_file, sr=None)
        print(f"Loaded audio shape: {y.shape}, Sample rate: {sr}")
        print(f"Max amplitude: {np.max(y)}, Min amplitude: {np.min(y)}")

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ĞµÑĞ»Ğ¸ ÑĞ¸Ğ³Ğ½Ğ°Ğ» Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹
        if len(y) == 0 or np.max(y) == 0:
            raise ValueError("Audio file is silent or empty!")

        # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ² Ğ¼ĞµĞ»-ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñƒ
        spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)
        print(f"Spectrogram shape: {spectrogram.shape}")
        print(f"Spectrogram max: {np.max(spectrogram)}, min: {np.min(spectrogram)}")

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ»Ğ¸ ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½ÑƒĞ»Ğ¸
        if np.max(spectrogram) > 0:
            normalized_spectrogram = spectrogram / np.max(spectrogram)  # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
        else:
            raise ValueError("Spectrogram contains only zeros! Check the audio file or preprocessing steps.")

        # Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñƒ
        plt.figure(figsize=(10, 4))
        librosa.display.specshow(librosa.power_to_db(spectrogram, ref=np.max),
                                 sr=sr, x_axis='time', y_axis='mel')
        plt.colorbar(format='%+2.0f dB')
        plt.title('Mel-Spectrogram (Debug)')
        plt.tight_layout()
        plt.show()

        return normalized_spectrogram
    except Exception as e:
        print(f"Error processing file {audio_file}: {e}")
        raise

# ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ±Ğ»Ğ¾Ğº
# Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
instrument_map = {
    'cel': 0, 'cla': 1, 'flu': 2, 'gac': 3, 'gel': 4,
    'org': 5, 'pia': 6, 'sax': 7, 'tru': 8, 'vio': 9, 'voi': 10
}

# Ğ˜Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ map
instrument_map_inv = {v: k for k, v in instrument_map.items()}

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»
test_audio_file = '/content/irmas_dataset/IRMAS-TrainingData/org/[org][jaz_blu]1045__2.wav'

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸
test_spectrogram = load_audio_and_convert_to_spectrogram_debug(test_audio_file)

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¾ÑÑŒ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
test_spectrogram = test_spectrogram[np.newaxis, ..., np.newaxis]

# Ğ”ĞµĞ»Ğ°ĞµĞ¼ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ
predicted_label = model.predict(test_spectrogram).argmax()
print(f"Predicted Instrument: {instrument_map_inv[predicted_label]}")

```

    Loaded audio shape: (132299,), Sample rate: 44100
    Max amplitude: 0.45159912109375, Min amplitude: -0.488983154296875
    Spectrogram shape: (128, 259)
    Spectrogram max: 305.1554260253906, min: 6.765408788744764e-10
    


    
![png](recog_doc_files/recog_doc_28_1.png)
    


    [1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
    Predicted Instrument: org
    
